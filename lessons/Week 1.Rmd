---
title: 'Week 1: Data Import, Manipulation, and GitHub'
output:
  output: rmarkdown::github_document
---

<!--
html_document:
    df_print: paged
  html_notebook: default
  pdf_document: default
-->

<!-- output: rmarkdown::github_document -->

# Objectives:

- Set up and configure GitHub for use within RStudio.  
- Importing data in R (a quick overview).  
- Data manipulation in R (a quick overview).

# Setup GitHub

Follow instructions on [Using Git with RStudio](https://jennybc.github.io/2014-05-12-ubc/ubc-r/session03_git.html). 

For a Windows machine, generally, it is:

- Download and install [Git](https://git-scm.com/download/win).  
- In RStudio, create an SSH key pair (follow instructions [here](https://happygitwithr.com/ssh-keys.html#create-an-ssh-key-pair)):  
  - Go to Tools > Global Options... > Git/SVN.  
  - Point to the executable "git.exe" (/Program Files/Git/)  
  - Create RSA key in RStudio.  
  - Copy RSA key. Add the generated key by clicking "new SSH key" into GitHub under your profile's settings > SSH and GPG keys, and pasting it.
- Open git bash executable, and change directory (`cd`) to the folder you want to save the repo in.  
- Run the following:  
```
git clone https://github.com/engineerchange/r-dsandml-exercises.git
```

- Open .Rproj file in RStudio.  
- Then go to Tools > Project Options... > Git/Svn to configure.  
- From there, you should see a "Git" tab in the Environment pane where you can Commit, Pull, and Push.  

# Importing 
<!-- read_csv, read_csv2, read_delim, data.table, dtplyr, arrow/parquet -->

Load in necessary libraries.

```{r, message=FALSE}
library(tidyverse)
library(arrow)
library(microbenchmark) # to do simple benchmarking
```

Tidyverse's read_csv() function, which is 10x faster than base's read.csv() function.

Compare both:  
```{r, message=FALSE}

func1 <- function(){read.csv2("lessons/data/DB_ESDO_FRANCE_2002-2011.csv")}
func2 <- function(){read_csv2("lessons/data/DB_ESDO_FRANCE_2002-2011.csv")}

microbenchmark(times=20, unit="ms", func1(), func2())
```

Can potentially speed up operations after by saving as RDS or arrow's parquet.

```{r, message=FALSE}

df = read_csv2("lessons/data/DB_ESDO_FRANCE_2002-2011.csv")

func1 <- function(){write_rds(df,"lessons/data/out.RDS")}
func2 <- function(){write_parquet(df,"lessons/data/out.parquet")}

microbenchmark(times=20, unit="ms", func1(), func2())

```

Can potentially speed up read times with parquet over standard RDS.

```{r, message=FALSE}

func1 <- function(){read_rds("lessons/data/out.RDS")}
func2 <- function(){read_parquet("lessons/data/out.parquet")}

microbenchmark(times=20, unit="ms", func1(), func2())
```

Try just reading in specific columns starting 

```{r, message=FALSE}

func1 <- function(){read_rds("lessons/data/out.RDS") %>% select(starts_with("QFRA"))}
func2 <- function(){read_parquet("lessons/data/out.parquet",col_select = starts_with("QFRA"))}

microbenchmark(times=20, unit="ms", func1(), func2())

```

# Data Manipulation

<!-- pivot_wider, pivot_longer, separate, unite -->

# Exploratory Data Analysis (EDA)

<!-- geom_point, geom_histogram, geom_boxplot, gt, left_join, anti_join -->


# Resources

## GitHub
- [Using Git with RStudio](https://jennybc.github.io/2014-05-12-ubc/ubc-r/session03_git.html), Jenny Bryan  
- [Happy Git with R](https://happygitwithr.com/), Jenny Bryan  

## Importing
- [R for Data Science - Data Import](https://r4ds.had.co.nz/data-import.html)  